<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
<link rel="stylesheet" href="style.css" type="text/css">

<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

    <title>Thesis Repository</title>
  </head>


  <body>
                  <nav class="navbar navbar-expand-lg navbar-light navbar-custom ">
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="navbarSupportedContent">
    <ul class="navbar-nav mr-auto">
      <li class="nav-item active">
        <a class="nav-link" href="index.html">Home <span class="sr-only">(current)</span></a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="diary.html">Diary</a>
      </li>
      <li class="nav-item dropdown">
        <a class="nav-link dropdown-toggle" href="phases.html" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
          Phases
        </a>
        <div class="dropdown-menu" aria-labelledby="navbarDropdown">
          <a class="dropdown-item" href="phase1.html">Phase 1</a>
          <a class="dropdown-item" href="phase2.html">Phase 2</a>
          <a class="dropdown-item" href="phase3.html">Phase 3</a>
        </div>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="meetings.html">Meetings</a>
      </li>
    </ul>
  </div>
</nav>


    <h1>Meetings</h1>

<div id="accordion">

  <div class="card">
    <div class="card-header" id="headingOne">
      <h5 class="mb-0">
        <button class="btn btn-link" data-toggle="collapse" data-target="#collapseOne" aria-expanded="true" aria-controls="collapseOne">
          Week #1 (01-14-20)
        </button>
      </h5>
    </div>

    <div id="collapseOne" class="collapse show" aria-labelledby="headingOne" data-parent="#accordion">
      <div class="card-body">
        <h2>Overview</h2>
        <p>The first part of the work implies doing something similar to what has been developed for CROCI: we need a class to extend another class, which implements one method only and expects to receive a CSV. This CSV file defines some citations, and its form depends on the data provider (so we expect National Institute of Health to use a specific data format, probably a csv or a json)</p>
        <h2>get_next_citation_data</h2>
        <div class="container codebg">
        <pre><code>
 def get_next_citation_data(self):
    row = self._get_next_in_file()

    while row is not None:
        citing = self.doi.normalise(row.get("citing_id"))
        cited = self.doi.normalise(row.get("cited_id"))

        if citing is not None and cited is not None:
            created = row.get("citing_publication_date")
            if not created:
                created = None

            cited_pub_date = row.get("cited_publication_date")
            if not cited_pub_date:
                timespan = None
            else:
                c = Citation(None, None, created, None, cited_pub_date, None, None, None, None, "", None, None, None, None, None)
                timespan = c.duration

            self.update_status_file()
            return citing, cited, created, timespan, None, None

        self.update_status_file()
        row = self._get_next_in_file()

    remove(self.status_file)
  </pre></code></div>
        <p>This function is the last step of <a href="https://github.com/opencitations/index/blob/master/croci/crowdsourcedcitationsource.py">index/croci/crowdsourcedcitationsource.py /</a>.
 It was developed to manage the particular CSV format that we expect for CROCI; it finds information to return. Indeed, the process expects a tuple of 6 values, derived from the citation source.
 In particular:
 <ol>
   <li>citing</li>
   <li>cited</li>
   <li>created</li>
   <li>timespan</li>
   <li>None</li>
   <li>None</li>
 </ol>
The last values are meant to represent additional info about whether the citation is a self citation and about citations between publications on the same journal. In both cases the value is "none" because in this moment we are not interested in this information.
</p>
<h2>The Project</h2>
<p>We have to implement a class aimed at extending this CSV citation file implementing a get_next_citation_data tailored on NIH dataset (and related file formats).</p>
<p>In the aforementioned function we have <em>c</em>: this is the python class managing the interaction with the datasource. Each class relates to a specific format (? "typology"), depending on the index to be created.</p>
<p>We are going to work on an already-existing environment where the introduction of a new datasource requires the crearion of a new class, aimed at extracting from the new source the same set of information that the process is supposed to manage. The system is higly "parameterized": it always expects to receive a 6-values tuple, and exectutes a specific set of actions, depending on the given values.
In particular, the plug-in to be developed should be able to extract form the NIH file format the same information required by the system, so to place it in the 6-element tuple. That's what also COCI does, but with JSON format.
</p>
<p>The 2 primary identifiers are aimed at identifying the citing and the cited entity, and they are not always doi. In this case, we may have PubMedID or PubMedCentralID.
One of the problems to be handled is that some of these citations may already be present in <a href="https://opencitations.net/">Open Citations</a>. For example, in COCI we have only doi-to-doi; in the NIH dataset we are going to import some articles probably have a doi, but it is exposed in a different way.
However, if they have a doi, it is should be specified among the article data; or, as an alternative, it is possible to go back to it through an external mapping dataset.</p>
<p> Another consistent problem to be considered is that the 6-values-tuple doesn't expect (nor store) information about the DOI, since it is structured to manage only the 6 aforementioned aspects.</p>
<p> We'll need to add the mapping information, since -once imported the dataset in Open Citations- the API used for the unification process needs to manage the identifiers. This issue has never been handled until now, since the already imported data didn't require to deal with it. </p>
<h2>Phases Of The Project</h2>
<ol>
  <li>Develop a software to read the datasource. We need the aforementioned class, in order to manage the new datasource. In this phase the index is not supposed to disambiguate: it has just to work in its own field.</li>
  <li>Develop a sub-index of indexes for the alignment phase, so to recognise and map possible resources referring to the same citation, despite having differen URLs. This plug-in is aimed at managing all the possible data sources, so that -in case we need to import a new dataset with a different identifier in future- we can reuse the same tool.</li>
  <li>API</li>
</ol>
<h2>Test Driven Development</h2>
<p>The 9th file in the test folder, <a href="https://github.com/opencitations/index/blob/master/test/09_croci.py">09_croci.py</a> provides a good example of the functioning of this kind of test. The procedure implies starting by creating a new class, which instantiates 2 functions: a set-up one and a test.</p>
<div class="container codebg">
<pre><code>
  import unittest
from index.coci.glob import process
from os import sep, makedirs
from os.path import exists
from shutil import rmtree
from index.storer.csvmanager import CSVManager
from index.croci.crowdsourcedcitationsource import CrowdsourcedCitationSource
from csv import DictReader


class CROCITest(unittest.TestCase):

    def setUp(self):
        self.input_file = "index%stest_data%scroci_dump%ssource.csv" % (sep, sep, sep)
        self.citations = "index%stest_data%scroci_dump%scitations.csv" % (sep, sep, sep)

    def test_citation_source(self):
        ccs = CrowdsourcedCitationSource(self.input_file)
        new = []
        cit = ccs.get_next_citation_data()
        while cit is not None:
            citing, cited, creation, timespan, journal_sc, author_sc = cit
            new.append({
                "citing": citing,
                "cited": cited,
                "creation": "" if creation is None else creation,
                "timespan": "" if timespan is None else timespan,
                "journal_sc": "no" if journal_sc is None else journal_sc,
                "author_sc": "no" if author_sc is None else author_sc
            })
            cit = ccs.get_next_citation_data()

        with open(self.citations) as f:
            old = list(DictReader(f))

        self.assertEqual(new, old)
</pre></code></div>

<h2>To do list</h2>
<ul>
  <li>create a repository, where the weekly report will be kept updated.</li>
  <li>write an e-mail to DARCH and ask for an intership (object: first phase of the thesis project, concerning the interaction with datasource).</li>
  <li>study the <a href="https://docs.python.org/3/library/unittest.html">unittest library</a> for tests and make some practice with it.</li>
  <li>have a look at CROCI test, which is simple and deals with a class which is similar to the one to be developed. Start with <a href="https://comp-think.github.io/">CT exercises</a> and reproduce the functions using unittest. Before writing the functions that the class implements, make sure to have the test written. Learn how to launch the library, how to use it proficiently.</li>
</ul>

      </div>
    </div>
  </div>

  <div class="card">
    <div class="card-header" id="headingTwo">
      <h5 class="mb-0">
        <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseTwo" aria-expanded="false" aria-controls="collapseTwo">
          Week #2 (01-21-21)
        </button>
      </h5>
    </div>
    <div id="collapseTwo" class="collapse" aria-labelledby="headingTwo" data-parent="#accordion">
      <div class="card-body">
          <h2>To do list</h2>
          <ul>
              <li>Extract ten examples of citational data from NIH library and try to understad the format of the data we are going to work with.</li>
              <li>Start preparing the data mapping: analyse your information in order to understand the mapping.</li>
              <li>Try to imagine how the main function has to be structured.</li>
              <li>Develop the test case, which is going to fail, since the function to be tested doesn't exist yet.</li>
              <li>Study basic commands of the command prompt (python -m unittest).</li>
              <li>Clone locally OC index so to run tests.</li>
              <li>Revise self citation aspect in COCI article (<a href="Heibi2019_Article_SoftwareReviewCOCITheOpenCitat.pdf">Software review: COCI, the OpenCitations Index of Crossref
open DOI‑to‑DOI citations</a>)</li>
          </ul>
        <h2>Comments to unittest working frame</h2>
          <p><strong>assertRaises():</strong> Checks whether a specific exception is raised by the execution of a specific code. Hoewever, in our case, even if we have exceptions, we don't need to test them, since our checks are strictly assertive, on data.
          <p><strong>if __name__ == '__main__ ':</strong> When we make imports, we have the possibility to perform them totally, with <strong>import *</strong>. However, when we import everything, we include also some lines of code we don't really need, such as prints and tests (when we import we are generally interested in functions and methods, not in tests and prints). For this reason, we have a method that allows us to specify that some lines of the code belong locally to a specific file: we can for example specify if __name__ == '__main__ ': do something (which means "do something only if you are processing this specific file, otherwise don't execute the unittest. Unittest has to be executed only if the specific file is the one which is called by the python interpreter).
          </p>
          <p><strong>assertEqual(first, second, msg=None):</strong>
Test that first and second are equal. If the values do not compare equal, the test will fail. This is the most widely used method of the unittesting framework. </p>
          <p>In OC we use Unittest because it comes in default with python, and it is enough for our needs.
          In the development of NOCI it will be necessary to mantain the same structure of the other tests, developing a test function for each method of the to be implemented (at least).</p>

          
        <h2> Analysis of get_next_citation_data test</h2>
         <p><strong>Sep sep sep:</strong> In setUp(self) function "%" is the separator. The problem of the separator could be be solved also with the filepath class.</p>
         <p><strong>setUp(self):</strong> In this function we take paths of the files that contain our sources and what we expect to obtain as a result. The input file is passed as a constructor: we want to take the source of the initial data. I pass this <strong>self.input_file</strong> as input to the <strong>CrowdsourcedCitationSource</strong> class in order to obtain initial data.</p>
         <p>At this point, we can create the citations, adapting them to what we have in our source file.
        <p><strong>cit = ccs.get_next_citation_data()</strong> bring us back to our 6-elements tuple.</p> 
        <p>If one between creation and timespan is missing, or if both of them are missing,that's not a big problem, and the field stays empty(e.g.:"creation": "" if creation is None else creation). In the other cases, if an element is missing, we need to add "no" to specify the absence of the element, in order to stay compliant with the OC format.</p>
          <p>One of the final steps implies saving the output file in the correct format( with open(self.citations) as f:
              <strong>old</strong> = list(DictReader(f))).</p>
         <p>At this point, we compare the old and new with the assertEqual method. We need to compare these 2 dictionaries in order to check if the sets are coherent.</p>
        
          <h2>Command Prompt</h2>
          <p>We need to know how to use the command propmpt because the test has to be run from the command line.The reason is that it makes possible to execute tests one by one instead of making a unique big test calling all the individual parts. For example, if we clone locally a git repository, from the outside of an index folder we can call python -m package (location where the test is placed). In this way we can run the specific test only.</p>
          
          <h2>Open Citation Environment: NOCI</h2>
          <p>The aim of this thesis project is to develop an extension of ocindex. For this reason, i need to clone locally oc index, so to be able to run tests. We will add a new directory, a package, that we can call "NOCI", that will be developed following CROCI structure. We will need a python file in order to interact with the input file containing NIH data (extend locally with a folder containing a python file named "nih citation source", or something similar). </p>
          <p>Initially, this won't work: the first thing we need to do after having the structure set is developing the test case, so to check that the input returns a specific output. The form of the output has to be defined (emulate CROCI and COCI). This process forces us to think about the format of input and output materials of the functio to be developed.  </p>
          <p>As we said, the output has to have the OC sixtuple format (see test data croci dump citation). The only big difference is that the value that I'm going to insert in citing and cited won't be a doi, but the NIH id, which should be a PubMed ID. The DOI may be (and probably is) present; however, we can't rely on this. In this dataset we will have the "selfcitation" info, but we don't know yet whether it is useful or not for our purposes. 
          <p>Remember that "Selfcitation" is set as "yes" if citing and cited either belong to the same journal or if there is at least a member in common between citing and cited authors. </p>
          
          
        <h2>Support files</h2>
            <p>Many of the information, if lacking, can be integrated in a further phase of the project, in which we can create support files in order to update the process.</p>
          <p>A support file is a csv file with very simple structure. In coci there is a glob.py file that creates those support files. Its aims:</p>
              <ul>
                  <li>check whether the specified DOIs are valid</li>
                  <li>map (id-pubdate; journal isn - other data; article id - related data </li>
          </ul> 
          <p>With the support file we try to understand if we can improve the quality of the info about the sixtuple.</p>
          <p>("id1", "id2", None, None, None, None) <br>
id_date.csv:
"id1","2019"
"id2","2017"
-> <br>
("id1", "id2", "2019", <strong>"P2Y"</strong>, None, None)</p>
          <p>Once we obtained somewhere else these data, we understand that the first id is associated with the date "2019", while the second one with the date "2017". In this way we can extend the citation data with the timespan info, that I didn't have before. </p>
              
          <p>However, the general process, when lacking a support file, tries to reconstruct the information using an API (the mechanism is like a switch: if we don't have the support file, we try with the API). All the tools that we have now were developed for the doi: now we have to do the same for the PubMed Ids. We may need another blob for NOCI, in order to generate additional csv, or maybe we can make request for already existing online API, so to obtain local files.  </p>
          
       <h2>Working process overview</h2>
          <ul>
              <li>Citation source works at least with 2 pieces of information: citing and cited. Also in the case it is the only material we have, we keep it.</li>
              <li> The overall process, in case we lack some piece of information, uses precomputed files that allow to improve the starting material.</li>
          </ul>
          
        <p>As first step, we have to understand what we have and what is missing. Then, we have to understand how to develop globs, global files. At this point we have to reason on PubMed Id structure, which is not handled by our OC general process, for now. All this stuff relates to the first phase. The following one is the alignment.</p>
          
        <h2>Links and References</h2>
          <ul>
              <li>index.test.01_csvmanager</li>
              <li><a href="https://github.com/opencitations/index">https://github.com/opencitations/index</a></li>
              <li><a href="https://github.com/opencitations/index/blob/master/test_data/croci_dump/citations.csv">https://github.com/opencitations/index/blob/master/test_data/croci_dump/citations.csv</a></li>
              <li><a href="https://github.com/opencitations/index/blob/master/coci/glob.py">https://github.com/opencitations/index/blob/master/coci/glob.py</a></li>    
          </ul>



      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingThree">
      <h5 class="mb-0">
        <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseThree" aria-expanded="false" aria-controls="collapseThree">
          Week #3 (02-5-21)
        </button>
      </h5>
    </div>
    <div id="collapseThree" class="collapse" aria-labelledby="headingThree" data-parent="#accordion">
      <div class="card-body">
          <h2>Mapping</h2>
          <h3>Reconstructing Information</h3>
          <p> We can work out the selfcitation information later. It would be reasonable to follow the same process adopted for COCI: we have a preprocessing phase where each document is associated to some information extracted form a csv file containing metadata (e.g. journal issn, orcid..). The algorithm is supposed to receive some files, then used to extract the selfcitation information. The point is that the mapping represents a further phase of the process.         
          </p>
          <h3>NIH Mapping file</h3>
          <p>NIH should provide a csv mapping file. We should then understand if it makes more sense using api or existing files (we don't know the number of files to be managed, but probably there are many of them - the APIs could be overloaded and if the same information is already stored in csv files the process should be faster).</p>
          
          <h2>NIH dataset management</h2>
          <p>The format we found for CROCI citational data was "citing" - "cited". While for NOCI it is "citing" - "referenced". The second part can't be changed, but muts be managed in the way it comes. Pay attention: <strong>the source file must stay as it is</strong>: the differring naming convention is to be managed in the 6-elements tuple.
          <h2> citing, cited, creation, timespan, journal_sc, author_sc = cit </h2>
          <p>The format of this assignment depends on the fact that I can associate tuples of variables to tuples of values, and cit is already a tuple of values, while citing, cited, creation, timespan, journal_sc, author_sc are the names of the variables.</p>

          <h2>c in the class CrowdsourcedCitationSource (crowdsourcedcitationsource.py)</h2>
          <p>Citations class. The passage with c is useful only because it tales the four main values. For example, Citations has in default the timespan step, and the constructor of the class makes calculations on its own. We keep only the part we need.</p>
          <h2>NOCI main function</h2>
          <p>Is to be developed on the base of the CROCI main function. It is the function that contains the NOCI class.</p>
          <p>The first aim of this function is managing the new type of id. This should happen in cnc.py. We are supposed to manage the type of id so to interact with the correct api. The most important aspect is that the conversion citation (source) -- information storing in the 6 columns format works. Once that we accomplish this aim, we have to understand how to improve the quality and the amount of data to be stored in the tuple. Use input files of CROCI to understand the functioning of the overall process. <strong>get_next_citation</strong> must mantain the same name in the new class to be implemented. </p>
          
          <h2>To do</h2>
          <ul>
              <li>Download Metadata File</li>
              <li>Develop the main function</li>
              <li>Correct the test function</li>
              <li>Locally clone and launch OC index</li>
              <li>Read Mail about mapping</li>
          </ul>
      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingFour">
      <h5 class="mb-0">
        <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseFour" aria-expanded="false" aria-controls="collapseFour">
          Week #4 (2021-02-11)
        </button>
      </h5>
    </div>
    <div id="collapseFour" class="collapse" aria-labelledby="headingFour" data-parent="#accordion">
      <div class="card-body">
          <h2>Normaliser</h2>
        <p><strong>Normaliser:</strong>Takes an ID assuming it is of a certain type. It then checks and uniforms it according to a unique scheme (which is slightly custumisable, but not so much). With dois, it takes as input a string and makes a normalisation by turning everything in lowercase and checks that there are no null charachters, which would break the id. So, in general, a normaliser takes as input an id ad gives back it in the normalised format.</p>
         
        <h2>Validator</h2>
        <p><stong>Validator:</stong> When the normaliser doesn't return none, the following steps are managed by the validator, which is strictly dependent on the object it works on. Some IDs formats follow a progressive logic, which make them validable against a particular scheme. However, some other ids like DOIs can be validated only by an API. </p>
        
        <h2>PubMed Case</h2>
          <p>^\d+$ --> 	^[1-9]\d*$ (non ^[0-9]{1,7}$)</p>
        
          <p> <strong>orcid_string = sub("[^X0-9]", "", id_string.upper())</strong>
           --> It may happen that the url of the orcid is passed (instead of the pure orcid, for example). The same thing may happen with pubmed id, so it should be managed. In our case, since pubmed id are made of digits only, we have to leave out everything except for digits. The idea is to remove everything that is not a digit. Moreover, we have to leave out the hypotetical sequence of 0s that we may find before the id.  At this point we can normalise (we won't need upper/lowercases normalisation, since we are managing digits only). For the validation we will need the PubMed API, in order to know whether the id exists or not.</p>
         
          <h2>to do</h2>
          <ol>
          <li>Fix the second function developed last time (id case is built on the base of doi case) </li>
          <li>Add a test case also for this latter function</li>
          <li>Look at the overall functioning: where do we need additional code to manage pubmeds?</li>
          <li>Run tests</li>
          <li>Before checking the overall functioning, check the two tests</li>
          </ol> 
      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingFive">
      <h5 class="mb-0">
        <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseFive" aria-expanded="false" aria-controls="collapseFive">
          Week #5 (2021-02-18)
        </button>
      </h5>
    </div>
    <div id="collapseFive" class="collapse" aria-labelledby="headingFive" data-parent="#accordion">
      <div class="card-body">
        Anim pariatur cliche reprehenderit, enim eiusmod high life accusamus terry richardson ad squid. 3 wolf moon officia aute, non cupidatat skateboard dolor brunch. Food truck quinoa nesciunt laborum eiusmod. Brunch 3 wolf moon tempor, sunt aliqua put a bird on it squid single-origin coffee nulla assumenda shoreditch et. Nihil anim keffiyeh helvetica, craft beer labore wes anderson cred nesciunt sapiente ea proident. Ad vegan excepteur butcher vice lomo. Leggings occaecat craft beer farm-to-table, raw denim aesthetic synth nesciunt you probably haven't heard of them accusamus labore sustainable VHS.
      </div>
    </div>
  </div>
  <div class="card">
    <div class="card-header" id="headingSix">
      <h5 class="mb-0">
        <button class="btn btn-link collapsed" data-toggle="collapse" data-target="#collapseSix" aria-expanded="false" aria-controls="collapseSix">
          Week #6
        </button>
      </h5>
    </div>
    <div id="collapseSix" class="collapse" aria-labelledby="headingSix" data-parent="#accordion">
      <div class="card-body">
        Anim pariatur cliche reprehenderit, enim eiusmod high life accusamus terry richardson ad squid. 3 wolf moon officia aute, non cupidatat skateboard dolor brunch. Food truck quinoa nesciunt laborum eiusmod. Brunch 3 wolf moon tempor, sunt aliqua put a bird on it squid single-origin coffee nulla assumenda shoreditch et. Nihil anim keffiyeh helvetica, craft beer labore wes anderson cred nesciunt sapiente ea proident. Ad vegan excepteur butcher vice lomo. Leggings occaecat craft beer farm-to-table, raw denim aesthetic synth nesciunt you probably haven't heard of them accusamus labore sustainable VHS.
      </div>
    </div>
  </div>
</div>




  </body>
</html>
